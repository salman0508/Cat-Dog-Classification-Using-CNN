{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0691b781",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fa38cb5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = 'E:/ML Internship/cat&dog/cats_dogs_light/train'\n",
    "test_path = 'E:/ML Internship/cat&dog/cats_dogs_light/test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e5a35b53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "completed \n",
      "completed \n"
     ]
    }
   ],
   "source": [
    "def preprocess_images(image_paths, target_size=(224, 224)):\n",
    "    processed_images = []\n",
    "    for path in image_paths:\n",
    "        image = cv2.imread(path)\n",
    "        resized_image = cv2.resize(image, target_size)\n",
    "        normalized_image = resized_image / 255.0\n",
    "        processed_images.append(normalized_image)\n",
    "    return processed_images\n",
    "\n",
    "def preprocess_dataset(dataset_path):\n",
    "    classes = os.listdir(dataset_path)\n",
    "    images = []\n",
    "    labels = []\n",
    "    for i, class_name in enumerate(classes):\n",
    "        class_path = os.path.join(dataset_path, class_name)\n",
    "        class_images = [os.path.join(class_path, img) for img in os.listdir(class_path)]\n",
    "        images.extend(class_images)\n",
    "        labels.extend([i] * len(class_images))  # Assign label based on class index\n",
    "    return preprocess_images(images), labels\n",
    "\n",
    "# Preprocess train, test, and val datasets\n",
    "X_train, y_train = preprocess_dataset(train_path)\n",
    "print(\"completed \")\n",
    "X_test, y_test = preprocess_dataset(test_path)\n",
    "print(\"completed \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b278b147",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "completed\n",
      "completed\n",
      "completed\n"
     ]
    }
   ],
   "source": [
    "X_train = np.array(X_train)\n",
    "print(\"completed\")\n",
    "y_train = np.array(y_train)\n",
    "print(\"completed\")\n",
    "X_test = np.array(X_test)\n",
    "print(\"completed\")\n",
    "y_test = np.array(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "691a14ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "3/3 [==============================] - 29s 10s/step - loss: 5.3686 - accuracy: 0.4500 - val_loss: 2.2197 - val_accuracy: 0.5000\n",
      "Epoch 2/20\n",
      "3/3 [==============================] - 30s 10s/step - loss: 2.1661 - accuracy: 0.5000 - val_loss: 1.9965 - val_accuracy: 0.5000\n",
      "Epoch 3/20\n",
      "3/3 [==============================] - 31s 11s/step - loss: 1.5544 - accuracy: 0.5000 - val_loss: 0.8420 - val_accuracy: 0.5000\n",
      "Epoch 4/20\n",
      "3/3 [==============================] - 33s 11s/step - loss: 0.5734 - accuracy: 0.7250 - val_loss: 0.5867 - val_accuracy: 0.7500\n",
      "Epoch 5/20\n",
      "3/3 [==============================] - 34s 12s/step - loss: 0.4456 - accuracy: 0.9000 - val_loss: 0.5435 - val_accuracy: 0.8000\n",
      "Epoch 6/20\n",
      "3/3 [==============================] - 33s 11s/step - loss: 0.3952 - accuracy: 0.9000 - val_loss: 0.4873 - val_accuracy: 0.9000\n",
      "Epoch 7/20\n",
      "3/3 [==============================] - 33s 11s/step - loss: 0.3047 - accuracy: 0.9875 - val_loss: 0.4600 - val_accuracy: 0.7500\n",
      "Epoch 8/20\n",
      "3/3 [==============================] - 34s 12s/step - loss: 0.2418 - accuracy: 0.9750 - val_loss: 0.4314 - val_accuracy: 0.7500\n",
      "Epoch 9/20\n",
      "3/3 [==============================] - 34s 12s/step - loss: 0.1765 - accuracy: 0.9875 - val_loss: 0.4023 - val_accuracy: 0.8000\n",
      "Epoch 10/20\n",
      "3/3 [==============================] - 34s 11s/step - loss: 0.1308 - accuracy: 1.0000 - val_loss: 0.3885 - val_accuracy: 0.8000\n",
      "Epoch 11/20\n",
      "3/3 [==============================] - 33s 11s/step - loss: 0.0987 - accuracy: 1.0000 - val_loss: 0.3789 - val_accuracy: 0.8000\n",
      "Epoch 12/20\n",
      "3/3 [==============================] - 34s 11s/step - loss: 0.0737 - accuracy: 1.0000 - val_loss: 0.3749 - val_accuracy: 0.8000\n",
      "Epoch 13/20\n",
      "3/3 [==============================] - 35s 12s/step - loss: 0.0563 - accuracy: 1.0000 - val_loss: 0.3774 - val_accuracy: 0.8000\n",
      "Epoch 14/20\n",
      "3/3 [==============================] - 34s 11s/step - loss: 0.0438 - accuracy: 1.0000 - val_loss: 0.3732 - val_accuracy: 0.8000\n",
      "Epoch 15/20\n",
      "3/3 [==============================] - 34s 12s/step - loss: 0.0345 - accuracy: 1.0000 - val_loss: 0.3719 - val_accuracy: 0.8000\n",
      "Epoch 16/20\n",
      "3/3 [==============================] - 34s 12s/step - loss: 0.0279 - accuracy: 1.0000 - val_loss: 0.3730 - val_accuracy: 0.8000\n",
      "Epoch 17/20\n",
      "3/3 [==============================] - 34s 12s/step - loss: 0.0231 - accuracy: 1.0000 - val_loss: 0.3765 - val_accuracy: 0.8000\n",
      "Epoch 18/20\n",
      "3/3 [==============================] - 34s 12s/step - loss: 0.0193 - accuracy: 1.0000 - val_loss: 0.3800 - val_accuracy: 0.8000\n",
      "Epoch 19/20\n",
      "3/3 [==============================] - 35s 12s/step - loss: 0.0164 - accuracy: 1.0000 - val_loss: 0.3837 - val_accuracy: 0.8000\n",
      "Epoch 20/20\n",
      "3/3 [==============================] - 35s 12s/step - loss: 0.0142 - accuracy: 1.0000 - val_loss: 0.3880 - val_accuracy: 0.8000\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000001D209171FC0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 7s 7s/step\n",
      "Accuracy: 0.9\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.applications import VGG16\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Flatten, Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from sklearn.metrics import accuracy_score\n",
    "import cv2\n",
    "\n",
    "# Assuming you have your features in X_train, X_test, y_train, and y_test\n",
    "\n",
    "# Load the VGG16 model pre-trained on ImageNet data\n",
    "base_model = VGG16(include_top=False, weights='imagenet', input_shape=(224, 224, 3))\n",
    "\n",
    "# Freeze the layers of the pre-trained model\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Create a new model by adding a few more layers on top of the pre-trained model\n",
    "model = Sequential([\n",
    "    base_model,\n",
    "    Flatten(),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=Adam(learning_rate=0.001),\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Define a checkpoint to save the model with the best validation accuracy\n",
    "checkpoint = ModelCheckpoint('best_model.h5', save_best_only=True, save_weights_only=False, monitor='val_accuracy', mode='max')\n",
    "\n",
    "# Train the model for 10 epochs\n",
    "history = model.fit(X_train, y_train, epochs=20, batch_size=32, validation_data=(X_test, y_test), callbacks=[checkpoint])\n",
    "\n",
    "# Load the best model (model with the highest validation accuracy)\n",
    "best_model = load_model('best_model.h5')\n",
    "\n",
    "# Evaluate the best model on the test set\n",
    "y_pred = best_model.predict(X_test)\n",
    "y_pred_binary = np.round(y_pred)  # Convert probabilities to binary predictions\n",
    "accuracy = accuracy_score(y_test, y_pred_binary)\n",
    "print(\"Accuracy:\", accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3097c133",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 520ms/step\n",
      "Predicted class: cat\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import load_model\n",
    "import cv2\n",
    "\n",
    "# Load the saved model\n",
    "loaded_model = load_model('best_model.h5')\n",
    "\n",
    "# Function to preprocess a single image\n",
    "def preprocess_image(image_path, target_size=(224, 224)):  # Adjust the target_size\n",
    "    image = cv2.imread(image_path)\n",
    "    resized_image = cv2.resize(image, target_size)\n",
    "    normalized_image = resized_image / 255.0\n",
    "    return np.expand_dims(normalized_image, axis=0)  # Add batch dimension\n",
    "\n",
    "# Path to the new image you want to predict\n",
    "new_image_path = 'C:/Users/92309/Downloads/output_faces/download.jpg'\n",
    "\n",
    "# Preprocess the new image\n",
    "new_image = preprocess_image(new_image_path)\n",
    "\n",
    "# Make predictions using the loaded model\n",
    "predictions = loaded_model.predict(new_image)\n",
    "predicted_class = \"cat\" if predictions[0][0] < 0.5 else \"dog\"\n",
    "\n",
    "print(\"Predicted class:\", predicted_class)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36a9140c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
